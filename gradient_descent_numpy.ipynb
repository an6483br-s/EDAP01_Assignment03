{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Linear Regression with Numpy\n",
    "We compute the regression line linking counts of letters in a text to counts of letter _a_. \n",
    "\n",
    "Book version 2024\n",
    "\n",
    "Author: Pierre Nugues"
   ],
   "id": "3b222f7526dc680b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modules\n",
    "We import the modules we need to run the program"
   ],
   "id": "3c6b7d455d26bdc2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "e8f44690cad86e1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Dataset\n",
    "\n",
    "We load the data and we possibly normalize it"
   ],
   "id": "c2bbabba6672fe65"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The English dataset\n",
    "\n",
    "Number of characters"
   ],
   "id": "cb8024b09b0912a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = [[1, 35680.0],\n",
    "     [1, 42514.0],\n",
    "     [1, 15162.0],\n",
    "     [1, 35298.0],\n",
    "     [1, 29800.0],\n",
    "     [1, 40255.0],\n",
    "     [1, 74532.0],\n",
    "     [1, 37464.0],\n",
    "     [1, 31030.0],\n",
    "     [1, 24843.0],\n",
    "     [1, 36172.0],\n",
    "     [1, 39552.0],\n",
    "     [1, 72545.0],\n",
    "     [1, 75352.0],\n",
    "     [1, 18031.0]]"
   ],
   "id": "1be4ab8c86f067eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Number of a's",
   "id": "f1ebd732d9b7a801"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y = [2217.0,\n",
    "     2761.0,\n",
    "     990.0,\n",
    "     2274.0,\n",
    "     1865.0,\n",
    "     2606.0,\n",
    "     4805.0,\n",
    "     2396.0,\n",
    "     1993.0,\n",
    "     1627.0,\n",
    "     2375.0,\n",
    "     2560.0,\n",
    "     4597.0,\n",
    "     4871.0,\n",
    "     1119.0]"
   ],
   "id": "36b35b97f2069543"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Function to normalize the data\n",
    "\n",
    "We divide by the maximal value of the column"
   ],
   "id": "b866a8b8bc2953d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def normalize(Xy):\n",
    "    maxima = np.amax(Xy, axis=0)\n",
    "    Xy = 1/maxima * Xy\n",
    "    return (Xy, maxima)"
   ],
   "id": "cc5380c0eac0afe7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We normalize",
   "id": "608469d5d7287b76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "normalized = True\n",
    "debug = False\n",
    "# Predictors\n",
    "X = np.array(X)\n",
    "# Response\n",
    "y = np.array([y]).T\n",
    "\n",
    "alpha = 1.0e-10\n",
    "if normalized:\n",
    "    X, maxima_X = normalize(X)\n",
    "    y, maxima_y = normalize(y)\n",
    "    maxima = np.concatenate((maxima_X, maxima_y))\n",
    "    alpha = 1.0\n",
    "    print(\"-Normalized-\")"
   ],
   "id": "a0043a3657a4e919"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X, y",
   "id": "1f1f54bf4f893d6e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to compute the sum of squared errors",
   "id": "65d98c86b7773d99"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sse(X, y, w):\n",
    "    error = y - X @ w\n",
    "    return error.T @ error"
   ],
   "id": "18fb646a0eb26c89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to predict values",
   "id": "e4fd4ee219e4050c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict(X, w):\n",
    "    return X @ w"
   ],
   "id": "a74102c3635eddb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Batch descent\n",
    "Function to apply a batch descent"
   ],
   "id": "1bce58b3ffefdf90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit_batch(X, y, alpha, w,\n",
    "              epochs=500,\n",
    "              epsilon=1.0e-5):\n",
    "    \"\"\"\n",
    "    Batch gradient descent\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param alpha:\n",
    "    :param w:\n",
    "    :param epochs:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logs\n",
    "    logs = []\n",
    "    alpha /= len(X)\n",
    "    for epoch in range(epochs):\n",
    "        error = predict(X, w) - y\n",
    "        gradient = X.T @ error\n",
    "        w = w - alpha * gradient\n",
    "        logs += (w, alpha, sse(X, y, w))\n",
    "        if np.linalg.norm(gradient) < epsilon:\n",
    "            break\n",
    "    print(\"Epoch\", epoch)\n",
    "    return w"
   ],
   "id": "360600421c38e583"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We apply a batch descent",
   "id": "76091225fe648d3b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"===Batch descent===\")\n",
    "w = np.zeros((X.shape[1], 1))\n",
    "w = fit_batch(X, y, alpha, w)\n",
    "print(\"Weights\", w)\n",
    "print(\"SSE\", sse(X, y, w))\n",
    "if normalized:\n",
    "    maxima = maxima.reshape(-1, 1)\n",
    "    w = maxima[-1, 0] * (w / maxima[:-1, 0:1])\n",
    "    print(\"Restored weights\", w)\n",
    "if debug:\n",
    "    print(\"Logs\", logs)"
   ],
   "id": "5e3448769185180e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We restore the coordinates",
   "id": "78d0a0eaeb669095"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_fig = [X[i][1] * maxima_X[1] for i in range(len(X))]\n",
    "y_fig = [yi * maxima_y for yi in y]"
   ],
   "id": "1193c88c37d38778"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We plot the coordinates and the line",
   "id": "de3f6224fe0d18b6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(x_fig, y_fig)\n",
    "plt.plot([min(x_fig), max(x_fig)],\n",
    "         [[1, min(x_fig)] @ w, [1, max(x_fig)] @ w])\n",
    "plt.show()"
   ],
   "id": "5617e0eb8ab9bca2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Showing the iterations",
   "id": "a891b6bae106c691"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The errors",
   "id": "14a97c9246d134af"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(range(len(logs[2::3])), logs[2::3], c='b', marker='x')\n",
    "plt.title(\"Batch gradient descent: Sum of squared errors\")\n",
    "plt.show()"
   ],
   "id": "438262c01ceff834"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(list(map(lambda pair: pair[0], logs[0::3])),\n",
    "         list(map(lambda pair: pair[1], logs[0::3])), marker='o')\n",
    "for i in range(len(logs[0::3])):\n",
    "    plt.annotate(i, xy=logs[0::3][i])\n",
    "plt.title(\"Batch gradient descent: Weights\")\n",
    "plt.show()"
   ],
   "id": "665d162d7f18c496"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Stochastic descent\n",
    "Function to apply a stochastic descent"
   ],
   "id": "f01ecd8c90e87d9c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit_stoch(X, y, alpha, w,\n",
    "              epochs=500,\n",
    "              epsilon=1.0e-5):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param alpha:\n",
    "    :param w:\n",
    "    :param epochs:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logs, logs_stoch\n",
    "    logs = []\n",
    "    logs_stoch = []\n",
    "    random.seed(0)\n",
    "    idx = list(range(len(X)))\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(idx)\n",
    "        for i in idx:\n",
    "            # error is a scalar\n",
    "            error = (predict(X[i], w) - y[i])[0]\n",
    "            gradient = error * X[i:i + 1].T\n",
    "            w = w - alpha * gradient\n",
    "            logs_stoch += (w, alpha, sse(X, y, w))\n",
    "        if np.linalg.norm(gradient) < epsilon:\n",
    "            break\n",
    "        logs += (w, alpha, sse(X, y, w))\n",
    "    print(\"Epoch\", epoch)\n",
    "    return w"
   ],
   "id": "7dc5e83d7424e519"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We apply a stochastic descent",
   "id": "280ade57519e478f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"===Stochastic descent===\")\n",
    "w = np.zeros((X.shape[1], 1))\n",
    "w = fit_stoch(X, y, alpha, w)\n",
    "print(\"Weights\", w)\n",
    "print(\"SSE\", sse(X, y, w))\n",
    "if normalized:\n",
    "    maxima = maxima.reshape(-1, 1)\n",
    "    w = maxima[-1, 0] * (w / maxima[:-1, 0:1])\n",
    "    print(\"Restored weights\", w)\n",
    "if debug:\n",
    "    print(\"Logs\", logs)\n",
    "    print(\"Logs stoch.\", logs_stoch)"
   ],
   "id": "700e3b67dce46843"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We plot the line",
   "id": "672f3307b5667499"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(x_fig, y_fig)\n",
    "plt.plot([min(x_fig), max(x_fig)],\n",
    "         [[1, min(x_fig)] @ w, [1, max(x_fig)] @ w])\n",
    "plt.show()"
   ],
   "id": "ee96008227894e2b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Showing the iterations",
   "id": "e58cafbca3fa9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The errors by epoch",
   "id": "f28f3f33fa06d4a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(range(len(logs[2::3])), logs[2::3], c='b', marker='x')\n",
    "plt.title(\"Stochastic gradient descent: Sum of squared errors\")\n",
    "plt.show()"
   ],
   "id": "b3e3497032c60ff7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The weight updates by epoch",
   "id": "bbea1b17764e5784"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(list(map(lambda pair: pair[0], logs[0::3])), list(\n",
    "    map(lambda pair: pair[1], logs[0::3])), marker='o')\n",
    "for i in range(len(logs[0::3])):\n",
    "    plt.annotate(i, xy=logs[0::3][i])\n",
    "plt.title(\"Stochastic gradient descent: Weights\")\n",
    "plt.show()"
   ],
   "id": "51f5673f07c195dc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The weight updates",
   "id": "6b5be06418fcb870"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(range(len(logs_stoch[2::3])), logs_stoch[2::3], c='b', marker='x')\n",
    "plt.title(\"Stochastic gradient descent: Sum of squared errors (individual updates)\")\n",
    "plt.show()"
   ],
   "id": "e010cb79185f7626"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The weight updates by individual update",
   "id": "a2ccd994b8bb5935"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(list(map(lambda pair: pair[0], logs_stoch[0::3])),\n",
    "         list(map(lambda pair: pair[1], logs_stoch[0::3])),\n",
    "         marker='o')\n",
    "plt.title(\"Stochastic gradient descent: Weights (individual updates)\")\n",
    "plt.show()"
   ],
   "id": "c19713250c2dcca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9d181af5d080e6df"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
