{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Linear Regression\n",
    "We compute the regression line linking counts of letters in a text to counts of letter _a_ using Python functions (no numpy).\n",
    "\n",
    "Author: Pierre Nugues"
   ],
   "id": "b1a7f782c6d72dd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Modules\n",
    "We import the modules we need to run the program"
   ],
   "id": "5e92c08a555b3a4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import random\n",
    "import vector  # vector operations using Python\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "6fb99db609f5f4a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## The Dataset\n",
    "\n",
    "We load the data and we possibly normalize it"
   ],
   "id": "6d3caec584959b9f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The English dataset",
   "id": "cbdc260d0d0a4632"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X = [[1, 35680.0],\n",
    "     [1, 42514.0],\n",
    "     [1, 15162.0],\n",
    "     [1, 35298.0],\n",
    "     [1, 29800.0],\n",
    "     [1, 40255.0],\n",
    "     [1, 74532.0],\n",
    "     [1, 37464.0],\n",
    "     [1, 31030.0],\n",
    "     [1, 24843.0],\n",
    "     [1, 36172.0],\n",
    "     [1, 39552.0],\n",
    "     [1, 72545.0],\n",
    "     [1, 75352.0],\n",
    "     [1, 18031.0]]"
   ],
   "id": "143e05f6c15d68bb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y = [2217.0,\n",
    "     2761.0,\n",
    "     990.0,\n",
    "     2274.0,\n",
    "     1865.0,\n",
    "     2606.0,\n",
    "     4805.0,\n",
    "     2396.0,\n",
    "     1993.0,\n",
    "     1627.0,\n",
    "     2375.0,\n",
    "     2560.0,\n",
    "     4597.0,\n",
    "     4871.0,\n",
    "     1119.0]"
   ],
   "id": "d365e4cf2b57483f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Function to normalize the data",
   "id": "47d41a6badfe3908"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def normalize(observations):\n",
    "    maxima = [max([obs[i] for obs in observations])\n",
    "              for i in range(len(observations[0]))]\n",
    "    return ([[obs[i] / maxima[i]\n",
    "              for i in range(len(observations[0]))] for obs in observations],\n",
    "            maxima)"
   ],
   "id": "5d964bf5748e36c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "normalized = True\n",
    "debug = False\n",
    "\n",
    "alpha = 1.0e-10\n",
    "if normalized:\n",
    "    X, maxima_X = normalize(X)\n",
    "    maxima_y = max(y)\n",
    "    y = [yi / maxima_y for yi in y]\n",
    "    maxima = maxima_X + [maxima_y]\n",
    "    alpha = 1.0\n",
    "    print(\"-Normalized-\")"
   ],
   "id": "ad791ec775cca681"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "X, y",
   "id": "6631b915b6c4f65c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to compute the sum of squared errors",
   "id": "c84c2344d93e47f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def sse(X, y, w):\n",
    "    error = vector.sub(y, vector.mul_mat_vec(X, w))\n",
    "    return vector.dot(error, error)"
   ],
   "id": "73f72af940a40460"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Function to predict values",
   "id": "a2cc9249db86e858"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def predict(X, w):\n",
    "    return vector.mul_mat_vec(X, w)"
   ],
   "id": "2c56f5c2e7bb7e50"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Stochastic descent\n",
    "Function to fit the data with a stochastic descent"
   ],
   "id": "cde8d0f68a87476e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit_stoch(X, y, alpha, w,\n",
    "              epochs=500,\n",
    "              epsilon=1.0e-5):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param alpha:\n",
    "    :param w:\n",
    "    :param epochs:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logs, logs_stoch\n",
    "    logs = []\n",
    "    logs_stoch = []\n",
    "    random.seed(0)\n",
    "    idx = list(range(len(X)))\n",
    "    for epoch in range(epochs):\n",
    "        random.shuffle(idx)\n",
    "        for i in idx:\n",
    "            y_hat = predict([X[i]], w)[0]\n",
    "            loss = y[i] - y_hat\n",
    "            gradient = vector.mul(loss, X[i])\n",
    "            w = vector.add(w, vector.mul(alpha, gradient))\n",
    "            logs_stoch += (w, alpha, sse(X, y, w))\n",
    "        if vector.norm(gradient) < epsilon:\n",
    "            print('Gradient', vector.norm(gradient))\n",
    "            break\n",
    "        logs += (w, alpha, sse(X, y, w))\n",
    "    print(\"Epoch\", epoch)\n",
    "    return w"
   ],
   "id": "203cf7e6c7ee732"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Batch descent\n",
    "Function to fit the data with a batch descent"
   ],
   "id": "9f0a695fef879c88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def fit_batch(X, y, alpha, w,\n",
    "              epochs=500,\n",
    "              epsilon=1.0e-5):\n",
    "    \"\"\"\n",
    "    Batch gradient descent\n",
    "    :param X:\n",
    "    :param y:\n",
    "    :param alpha:\n",
    "    :param w:\n",
    "    :param epochs:\n",
    "    :param epsilon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logs\n",
    "    logs = []\n",
    "    alpha /= len(X)\n",
    "    for epoch in range(epochs):\n",
    "        y_hat = predict(X, w)\n",
    "        loss = vector.sub(y, y_hat)\n",
    "        gradient = vector.mul_mat_vec(vector.transpose(X), loss)\n",
    "        w = vector.add(w, vector.mul(alpha, gradient))\n",
    "        logs += (w, alpha, sse(X, y, w))\n",
    "        if vector.norm(gradient) < epsilon:\n",
    "            break\n",
    "    print(\"Epoch\", epoch)\n",
    "    return w"
   ],
   "id": "6feae8a92f0d02c8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We apply a batch descent",
   "id": "425e30d292944132"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"===Batch descent===\")\n",
    "w = [0.0] * (len(X[0]))\n",
    "w = fit_batch(X, y, alpha, w)\n",
    "print(\"Weights\", w)\n",
    "print(\"SSE\", sse(X, y, w))\n",
    "if normalized:\n",
    "    w = [w[i] * maxima[-1] / maxima[i] for i in range(len(w))]\n",
    "    print(\"Restored weights\", w)\n",
    "if debug:\n",
    "    print(\"Logs\", logs)"
   ],
   "id": "b301734b0db3331b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We restore the coordinates",
   "id": "bc55e442ee586d7e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "x_fig = [X[i][1] * maxima_X[1] for i in range(len(X))]\n",
    "y_fig = [yi * maxima_y for yi in y]"
   ],
   "id": "344c70d0f71b01f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We plot the coordinates and the line",
   "id": "2c7596f5c9d84b9e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(x_fig, y_fig)\n",
    "plt.plot([min(x_fig), max(x_fig)],\n",
    "         [vector.dot([1, min(x_fig)], w),\n",
    "          vector.dot([1, max(x_fig)], w)])\n",
    "plt.show()"
   ],
   "id": "9dcf9a0272d4ee17"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Showing the iterations",
   "id": "f251edcf8f819a40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The errors",
   "id": "fec43f8376b1dd01"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(range(len(logs[2::3])), logs[2::3], c='b', marker='x')\n",
    "plt.title(\"Batch gradient descent: Sum of squared errors\")\n",
    "plt.show()"
   ],
   "id": "d6ab088cadeea59a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(list(map(lambda pair: pair[0], logs[0::3])), list(\n",
    "    map(lambda pair: pair[1], logs[0::3])), marker='o')\n",
    "for i in range(len(logs[0::3])):\n",
    "    plt.annotate(i, xy=logs[0::3][i])\n",
    "plt.title(\"Batch gradient descent: Weights\")\n",
    "plt.show()"
   ],
   "id": "9ef60089b2d58"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We apply a stochastic descent",
   "id": "8772e7e2f9066b2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(\"===Stochastic descent===\")\n",
    "w = [0.0] * (len(X[0]))\n",
    "w = fit_stoch(X, y, alpha, w)\n",
    "print(\"Weights\", w)\n",
    "print(\"SSE\", sse(X, y, w))\n",
    "if normalized:\n",
    "    w = [w[i] * maxima[-1] / maxima[i] for i in range(len(w))]\n",
    "    print(\"Restored weights\", w)\n",
    "if debug:\n",
    "    print(\"Logs\", logs)\n",
    "    print(\"Logs stoch.\", logs_stoch)"
   ],
   "id": "949f5053c2836475"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## We plot the line",
   "id": "dddc0335c882a29b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(x_fig, y_fig)\n",
    "plt.plot([min(x_fig), max(x_fig)],\n",
    "         [vector.dot([1, min(x_fig)], w),\n",
    "          vector.dot([1, max(x_fig)], w)])\n",
    "plt.show()"
   ],
   "id": "96beddb5cc96924b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Showing the iterations",
   "id": "42e0ca094a6e8ab5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The errors by epoch",
   "id": "ca53a46651939ace"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(range(len(logs[2::3])), logs[2::3], c='b', marker='x')\n",
    "plt.title(\"Stochastic gradient descent: Sum of squared errors\")\n",
    "plt.show()"
   ],
   "id": "149ca219485a9779"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The weight updates by epoch",
   "id": "5f2939a8115233a9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(list(map(lambda pair: pair[0], logs[0::3])), list(\n",
    "    map(lambda pair: pair[1], logs[0::3])), marker='o')\n",
    "for i in range(len(logs[0::3])):\n",
    "    plt.annotate(i, xy=logs[0::3][i])\n",
    "plt.title(\"Stochastic gradient descent: Weights\")\n",
    "plt.show()"
   ],
   "id": "301bf02a04b127c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The weight updates",
   "id": "72c8c1e955762482"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.scatter(range(len(logs_stoch[2::3])), logs_stoch[2::3], c='b', marker='x')\n",
    "plt.title(\"Stochastic gradient descent: Sum of squared errors (individual updates)\")\n",
    "plt.show()"
   ],
   "id": "927c3d099d25dfcb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The weight updates by individual update",
   "id": "193fc7eb5f75c069"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.plot(list(map(lambda pair: pair[0], logs_stoch[0::3])), list(map(lambda pair: pair[1], logs_stoch[0::3])),\n",
    "         marker='o')\n",
    "plt.title(\"Stochastic gradient descent: Weights (individual updates)\")\n",
    "plt.show()"
   ],
   "id": "e49036a69bc7f464"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1d67e452a09c7dc8"
  }
 ],
 "metadata": {},
 "nbformat": 5,
 "nbformat_minor": 9
}
